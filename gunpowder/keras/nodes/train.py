import logging
import os
import numpy as np

from gunpowder.array import ArrayKey, Array
from gunpowder.ext import tensorflow as tf
from gunpowder.ext import keras
from gunpowder.nodes.generic_train import GenericTrain

logger = logging.getLogger(__name__)

class Train(GenericTrain):
    '''Keras implementation of :class:`gunpowder.nodes.GenericTrain`.

    Args:

        model_file (``string``):

            Filename of a Keras model as created by ``model.save()``.

        x (``dict``, ``string`` -> :class:`ArrayKey`):

            Dictionary mapping names of inputs (``x`` in keras) of the network
            to array keys.

        y (``dict``, ``string`` -> :class:`ArrayKey`):

            Dictionary mapping names of expected outputs (target values, ``y``
            in keras) of the network to array keys.

        outputs (``dict``, ``string`` -> :class:`ArrayKey`):

            Dictionary mapping names of outputs (not ``y``, but the actual
            predictions) of the network to array keys. New arrays will be
            generated by this node for each entry (if requested downstream).

        array_specs (``dict``, :class:`ArrayKey` -> :class:`ArraySpec`, optional):

            Used to set the specs of generated arrays (``outputs``). This is
            useful to set the ``voxel_size``, for example, if they differ from
            the voxel size of the input arrays. Only fields that are not
            ``None`` in the given :class:`ArraySpec` will be used.

        save_every (``int``, optional):

            After how many iterations to create a checkpoint to store the
            learnt weights.
    '''

    def __init__(
            self,
            model_file,
            x, y,
            outputs,
            array_specs=None,
            save_every=2000):

        super(Train, self).__init__(
            x,
            outputs,
            {},  # no gradients for Keras node
            array_specs,
            spawn_subprocess=False)

        self.model_file = model_file
        self.x = x
        self.y = y
        self.save_every = save_every

        self.iteration = 0
        self.model = None

    def start(self):

        checkpoint, self.iteration = self._get_latest_checkpoint(self.model_file)

        if checkpoint is not None:
            logger.info("Resuming training from iteration %d", self.iteration)
            self.model = keras.models.load_model(checkpoint)
        else:
            logger.info("Starting training from scratch")
            self.model = keras.models.load_model(self.model_file)

        self.model.summary()

    def stop(self):

        self.model = None

    def train_step(self, batch, request):

        x = self.__collect_provided_inputs(batch)
        y = self.__collect_provided_outputs(batch)

        metrics = self.model.train_on_batch(x, y)

        requested_outputs = self.__collect_requested_outputs(request)
        if requested_outputs:

            predictions = {
                name: array
                for name, array in zip(
                    self.model.output_names,
                    self.model.predict_on_batch(x))
            }

            for array_key, array_name in requested_outputs.items():
                spec = self.spec[array_key].copy()
                spec.roi = request[array_key].roi
                batch.arrays[array_key] = Array(
                    predictions[array_name],
                    spec)

        if len(self.model.metrics_names) > 1:
            batch.loss = metrics[0]
        else:
            batch.loss = metrics

        self.iteration += 1
        batch.iteration = self.iteration

        if batch.iteration%self.save_every == 0:

            checkpoint_name = self._checkpoint_name(
                self.model_file,
                batch.iteration)

            logger.info("Creating checkpoint %s", checkpoint_name)

            self.model.save(checkpoint_name)

    def __collect_requested_outputs(self, request):

        array_outputs = {}

        for output_name, array_key in self.outputs.items():
            if array_key in request:
                array_outputs[array_key] = output_name

        return array_outputs

    def __collect_provided_inputs(self, batch):

        return self.__collect_provided_arrays(batch, self.x, 'input_')

    def __collect_provided_outputs(self, batch):

        return self.__collect_provided_arrays(batch, self.y, '')

    def __collect_provided_arrays(self, batch, reference, prefix):

        arrays = {}

        for array_name, array_key in reference.items():
            if isinstance(array_key, ArrayKey):
                if array_key in batch.arrays:
                    arrays[prefix + array_name] = batch.arrays[array_key].data
                else:
                    logger.warning(
                        "batch does not contain %s, array %s will not be "
                        "set", array_key, array_name)
            elif isinstance(array_key, np.ndarray):
                arrays[prefix + array_name] = array_key
            elif isinstance(array_key, str):
                arrays[prefix + array_name] = getattr(batch, array_key)
            else:
                raise Exception(
                    "Unknown network array key {}, can't be given to "
                    "network".format(array_key))

        return arrays
